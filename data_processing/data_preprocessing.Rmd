---
title: "Untitled"
output: html_document
date: "2025-03-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library

The following library is used for processing the raw data acquired from [inside airbnb](https://insideairbnb.com/get-the-data)

```{r message=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(RSQLite)

options(scipen = 999)
```


# Listing

The listing data contains information regarding the listing or the property rented and its respective host. We will separate into several table:

* listing
* amenities
* host

## Read Data

```{r}
df_listing <- read.csv("../data/listings_sg.csv")

glimpse(df_listing)
```

## Amenities

Here we will create a table to store amenities provided by each listing.

```{r}
df_amenities <- df_listing %>% 
  select(listing_id = id, amenities) %>% 
  separate_rows(amenities,
                sep = '",'
                ) %>% 
  mutate(amenities = amenities %>% 
           str_remove_all('"') %>% 
           str_remove_all("\\[|\\]") %>% 
           str_trim()
         ) %>% 
  filter(!amenities %in% c("", "N/A")) 

df_amenities %>% 
  count(amenities, sort =T)
```

## Host

Here we will create a table to store information about the host.

```{r warning=FALSE}
master_host <- df_listing %>% 
  select(host_id,
         host_name,
         host_picture_url,
         host_identity_verified,
         host_is_superhost,
         host_neighbourhood,
         host_response_time,
         host_response_rate,
         host_since,
         host_about,
         host_url
         ) %>% 
  distinct() %>% 
  mutate(host_response_rate = host_response_rate %>% 
           str_remove_all("[%]") %>% 
           as.numeric()
         ) %>% 
  mutate_at(vars(host_identity_verified, host_is_superhost),
            function(x) case_when(x == "t" ~ T,
                                  x == "f" ~ F
                                  )
            ) %>% 
  mutate_if(is.character,
            function(x) if_else(x %in% c("", "N/A"), NA, x)
            )

master_host %>% 
  glimpse()
```

## Clean Listing

Here we will create a listing table with selected columns. We will only store columns that will be relevant for the dashboard.

```{r}
df_clean_listing <- df_listing %>% 
  transmute(id,
             listing_url,
            host_id,
             name,
             description,
             neighborhood_overview,
             picture_url,
             neighbourhood = neighbourhood_cleansed,
             latitude,
             longitude,
             property_type,
             room_type,
             accommodates,
             bathrooms,
             bathrooms_text,
             bedrooms,
             beds,
             license,
             instant_bookable,
             review_scores_rating,
             review_scores_accuracy,
            review_scores_cleanliness,
            review_scores_checkin,
            review_scores_communication,
            review_scores_location,
            review_scores_value
             ) %>% 
  mutate_if(is.character,
            function(x) if_else(x %in% c("", "N/A"), NA, x)
            ) %>% 
  mutate_at(vars(instant_bookable),
            function(x) case_when(x == "t" ~ T,
                                  x == "f" ~ F
                                  )
            )

df_clean_listing %>% 
  glimpse()
```

## SQLite

### Setup SQLite

Here we will store the data into sqlite


```{r}
# Create a connection to a new SQLite file
db_path <- "../data/airbnb_sg.sqlite"

conn <- dbConnect(SQLite(), db_path)

# Check if the connection is successful
dbListTables(conn)
```

### Clean Listing

Store the clean listing table

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          listing (id INTEGER PRIMARY KEY, 
                   listing_url TEXT,
                   host_id INTEGER,
                   name TEXT,
                   description TEXT,
                   neighborhood_overview TEXT,
                   picture_url TEXT,
                   neighbourhood TEXT,
                   latitude NUMERIC,
                   longitude NUMERIC,
                   property_type TEXT,
                   room_type TEXT,
                   accommodates INTEGER,
                   bathrooms NUMERIC,
                   bathrooms_text TEXT,
                   bedrooms INTEGER,
                   beds INTEGER,
                   license TEXT,
                   instant_bookable INTEGER,
                   review_scores_rating NUMERIC,
                   review_scores_accuracy NUMERIC,
                   review_scores_cleanliness NUMERIC,
                   review_scores_checkin NUMERIC,
                   review_scores_communication NUMERIC,
                   review_scores_location NUMERIC,
                   review_scores_value NUMERIC
                    )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "listing", 
             df_clean_listing, 
             append = TRUE, row.names = FALSE
             )

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM listing") %>% 
  glimpse()

```

### Host

Store the host table

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          host (host_id INTEGER PRIMARY KEY, 
                        host_name TEXT, 
                        host_picture_url TEXT, 
                        host_identity_verified TEXT,
                        host_is_superhost TEXT,
                        host_neighbourhood TEXT,
                        host_response_time TEXT,
                        host_response_rate NUMERIC,
                        host_since TEXT,
                        host_about TEXT,
                        host_url TEXT
                      )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "host", master_host, append = TRUE, row.names = FALSE)

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM host")

```

## Amenities

Store the amenities table

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          amenities (listing_id INTEGER, 
                      amenities TEXT
                      )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "amenities", df_amenities, append = TRUE, row.names = FALSE)

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM amenities")

```

# Review

## Read Data

Let's continue by reading the reviews data

```{r}
df_review <- read.csv("../data/reviews_sg.csv")

glimpse(df_review)
```

## Master User

Create a user table using the `reviewer_id` and `reviewer_name` from the review data

```{r}
master_user <- df_review %>% 
  distinct(reviewer_id, reviewer_name)

master_user
```

## Clean Review

We will create a new column named sentiment, which is predicted using ROBERTA model from [Hugging Face](https://huggingface.co/cardiffnlp/twitter-roberta-base). Here, we clean up the review data by removing irrelevant comment and save it to another csv to be used for prediction with python and done in Google Colab.

```{r}
df_clean_review <- df_review %>% 
  select(listing_id,
         id,
         reviewer_id,
         comments
         ) %>% 
  mutate_if(is.character,
            function(x) if_else(x %in% c("", "N/A", "n/a", "None"), NA, x)
            ) %>% 
  drop_na() 

df_clean_review %>% 
  write_csv("../data/clean_review_sg.csv", na = "")
```

## SQLite

### Master user

Create and insert user table

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          user (user_id INTEGER PRIMARY KEY, 
                name TEXT
                )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "user", master_user %>% rename(user_id = reviewer_id, name = reviewer_name), 
             append = TRUE, row.names = FALSE
             )

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM user")

```

### Review

The following is the processed data from Google Colab with a sentiment column

```{r}
df_sentiment_review <- read.csv("../data/clean_review_sg_with_sentiment.csv") %>% 
  filter(sentiment != "") %>% 
  left_join(df_review %>% 
              select(id, date_review = date),
            by = join_by(id)
            )

glimpse(df_sentiment_review)
```

Insert the data into review table

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          review (listing_id INTEGER,
                  id INTEGER PRIMARY KEY,
                  reviewer_id INTEGER,
                  comments TEXT,
                  sentiment TEXT,
                  date_review TEXT
                    )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "review", 
             df_sentiment_review, 
             append = TRUE, row.names = FALSE
             )

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM review")

```


# Calendar

## Read Data

Calendar data refers to the availability and priec of each listing on particular date. This is by far the biggest data in this project with over 1 million rows.

```{r}
df_calendar <- read.csv("../data/calendar_sg.csv")

glimpse(df_calendar)
```

Clean up and prepare the data

```{r}
df_clean_calendar <- df_calendar %>% 
  transmute(listing_id,
            date_period = date,
            available,
            price = price %>% 
              str_remove_all("[$,]") %>% 
              as.numeric(),
            
            adjusted_price = adjusted_price %>% 
              str_remove_all("[$,]") %>% 
              as.numeric(),
            
            minimum_nights,
            
            maximum_nights
            ) %>% 
    mutate_at(vars(available),
              function(x) case_when(x == "t" ~ T,
                                    x == "f" ~ F
                                    )
              )

df_clean_calendar %>% 
  glimpse()
```

## SQLite

### Calendar

Insert calendar into sqlite

```{r}
# Create a table
dbExecute(conn, "CREATE TABLE 
          listing_calendar (listing_id INTEGER, 
                            date_period TEXT,
                            available INTEGER,
                            price NUMERIC,
                            adjusted_price NUMERIC,
                            minimum_nights INTEGER,
                            maximum_nights INTEGER
                            )"
          )

# Write the entire data.frame to SQLite (Creates table if it doesn't exist)
dbWriteTable(conn, "listing_calendar", 
             df_clean_calendar, 
             append = TRUE, row.names = FALSE
             )

# Check if data was inserted
dbGetQuery(conn, "SELECT * FROM listing_calendar")

```
